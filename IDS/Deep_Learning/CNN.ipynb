{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EK9wkO-Qke1m"
   },
   "outputs": [],
   "source": [
    "# Dataset Path\n",
    "DatasetPath = \"E:/An toàn thông tin/Code/Dataset/NSL-KDD Processed/Final - For Using/\"\n",
    "train_dataset_path = DatasetPath + \"Trainset/\" + \"IDS.csv\"\n",
    "test_dataset_path = DatasetPath + \"Testset/\" + \"KDDTest+.csv\"\n",
    "\n",
    "# Save Model Path\n",
    "SavedModelPath = \"E:/An toàn thông tin/Code/Saved Model/IDSModel/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J7xxmAyY_7BN"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras.layers.normalization'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend \u001b[38;5;28;01mas\u001b[39;00m K\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense, Activation, Flatten, Conv1D, Dropout\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnormalization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BatchNormalization\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential, load_model\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EarlyStopping\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras.layers.normalization'"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "import os\n",
    "from keras import backend as K\n",
    "from keras.layers import Dense, Activation, Flatten, Conv1D, Dropout\n",
    "#from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement BatchNormalization (from versions: none)\n",
      "ERROR: No matching distribution found for BatchNormalization\n"
     ]
    }
   ],
   "source": [
    "pip install BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phiên bản Keras: 2.15.0\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "print(\"Phiên bản Keras:\", keras.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras.layers.normalization'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnormalization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BatchNormalization\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras.layers.normalization'"
     ]
    }
   ],
   "source": [
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_only(path, attack_category):\n",
    "    if attack_category != 'DOS' and attack_category != 'U2R_AND_R2L':\n",
    "      raise ValueError(\"Preprocess Data Fail: Invalid Attack Category\")\n",
    "    df = pd.read_csv(path)\n",
    "    df = df[df['class'].isin(['Normal', attack_category])]\n",
    "    print(f\" - Amount of Normal record: {len(df[df['class'] == 'Normal'])}\")\n",
    "    print(f\" - Amount of {attack_category} record: {len(df[df['class'] == attack_category])}\")\n",
    "    X = np.asarray(df[df.columns[df.columns != \"class\"]])\n",
    "    Y = np.asarray(df['class'].map(lambda x : 0 if x == \"Normal\" else 1))\n",
    "    return X, Y\n",
    "def load_dataset(path, attack_category):\n",
    "    X, Y = load_dataset_only(path, attack_category)\n",
    "    num_classes = 2\n",
    "    img_rows, img_cols = 1, X.shape[1]\n",
    "    X = X.reshape(X.shape[0], img_cols, img_rows)\n",
    "    Y = keras.utils.to_categorical(np.asarray(Y), num_classes)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uJKmEl03kUNj"
   },
   "source": [
    "#**1. Define Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 342
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3550,
     "status": "ok",
     "timestamp": 1594947795597,
     "user": {
      "displayName": "Tien LE KHAC",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhATILfEwLuvrRlBGPMrmY7nclZNsxGKzoqqHB_Cg=s64",
      "userId": "18298916241916904857"
     },
     "user_tz": -420
    },
    "id": "xKCcIzhhkW3M",
    "outputId": "2d6c6f1b-f272-4287-c64d-973acb8f645c"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Create Model\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSequential\u001b[49m()\n\u001b[0;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Conv1D(\u001b[38;5;241m128\u001b[39m, (\u001b[38;5;241m4\u001b[39m), input_shape\u001b[38;5;241m=\u001b[39m(img_cols, img_rows), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtanh\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Flatten())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "img_rows, img_cols = 1, 41\n",
    "num_classes = 2\n",
    "\n",
    "# Create Model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(128, (4), input_shape=(img_cols, img_rows), activation='tanh'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(optimizer=opt,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics= ['accuracy']\n",
    "            )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tSizIrGmm0tY"
   },
   "source": [
    "#**Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 667
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 46622,
     "status": "ok",
     "timestamp": 1594948223283,
     "user": {
      "displayName": "Tien LE KHAC",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhATILfEwLuvrRlBGPMrmY7nclZNsxGKzoqqHB_Cg=s64",
      "userId": "18298916241916904857"
     },
     "user_tz": -420
    },
    "id": "AOdsSiIgQMPH",
    "outputId": "d76bda9d-437b-4ba4-86d8-5ad91ac2eab0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Model: CNN, Attack Category: DOS\n",
      "Trainset\n",
      " - Amount of Normal record: 33671\n",
      " - Amount of DOS record: 22963\n",
      "Testset\n",
      " - Amount of Normal record: 9711\n",
      " - Amount of DOS record: 7460\n",
      "Train on 42475 samples, validate on 14159 samples\n",
      "Epoch 1/10\n",
      "42475/42475 [==============================] - 11s 268us/step - loss: 0.0107 - accuracy: 0.9962 - val_loss: 0.0204 - val_accuracy: 0.9948\n",
      "Epoch 2/10\n",
      "42475/42475 [==============================] - 11s 266us/step - loss: 0.0093 - accuracy: 0.9970 - val_loss: 0.0222 - val_accuracy: 0.9911\n",
      "Epoch 00002: early stopping\n",
      "17171/17171 [==============================] - 1s 54us/step\n",
      "Loss: 0.47 - Acc: 91.37%\n",
      "Saved model to disk\n",
      " Folder: /content/drive/My Drive/Study/KLTN/Saved Model/IDSModel/DOSDeep_Learning/Keras/\n",
      " Name: created_date_2020-07-17_CNN.h5\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model: CNN, Attack Category: U2R_AND_R2L\n",
      "Trainset\n",
      " - Amount of Normal record: 33671\n",
      " - Amount of U2R_AND_R2L record: 523\n",
      "Testset\n",
      " - Amount of Normal record: 9711\n",
      " - Amount of U2R_AND_R2L record: 2952\n",
      "Train on 25645 samples, validate on 8549 samples\n",
      "Epoch 1/10\n",
      "25645/25645 [==============================] - 7s 271us/step - loss: 0.0630 - accuracy: 0.9794 - val_loss: 0.0362 - val_accuracy: 0.9855\n",
      "Epoch 2/10\n",
      "25645/25645 [==============================] - 7s 271us/step - loss: 0.0271 - accuracy: 0.9897 - val_loss: 0.0213 - val_accuracy: 0.9926\n",
      "Epoch 3/10\n",
      "25645/25645 [==============================] - 7s 267us/step - loss: 0.0243 - accuracy: 0.9904 - val_loss: 0.0224 - val_accuracy: 0.9895\n",
      "Epoch 00003: early stopping\n",
      "12663/12663 [==============================] - 1s 53us/step\n",
      "Loss: 2.05 - Acc: 76.40%\n",
      "Saved model to disk\n",
      " Folder: /content/drive/My Drive/Study/KLTN/Saved Model/IDSModel/U2R_AND_R2LDeep_Learning/Keras/\n",
      " Name: created_date_2020-07-17_CNN.h5\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "today = str(date.today())\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "\n",
    "for attack_category in ['DOS', 'U2R_AND_R2L']:\n",
    "    print(f\"{100*'-'}\\nModel: CNN, Attack Category: {attack_category}\")\n",
    "    # Load data\n",
    "    print(\"Trainset\")\n",
    "    x_train, y_train = load_dataset(trainset_path,attack_category)\n",
    "    print(\"Testset\")\n",
    "    x_test, y_test = load_dataset(testset_path,attack_category)\n",
    "    # Train Model\n",
    "    model.fit(x_train,\n",
    "            y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            verbose=1,\n",
    "            validation_split=0.25,\n",
    "            callbacks=[es])\n",
    "\n",
    "    result = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "    print(f\"Loss: {result[0]:.2f} - Acc: {result[1]*100:.2f}%\")\n",
    "    model_saved_name = str(f\"created_date_{today}_CNN.h5\")\n",
    "    model_saved_folder = str(f\"{save_model_path}{attack_category}/Deep_Learning/Keras/\")\n",
    "    if not os.path.exists(model_saved_folder):\n",
    "                os.makedirs(model_saved_folder)\n",
    "    model.save(f\"{model_saved_folder}{model_saved_name}\")\n",
    "    print(f\"Saved model to disk\\n Folder: {model_saved_folder}\\n Name: {model_saved_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TxzZlstwWS3c"
   },
   "source": [
    "Thư mục lưu sai, đã chỉnh lại code và move model về đúng thư mục.  \n",
    "\"/content/drive/My Drive/Study/KLTN/Saved Model/IDSModel/***DOSDeep_Learning***/Keras/\"  \n",
    "--> /content/drive/My Drive/Study/KLTN/Saved Model/IDSModel/***DOS/Deep_Learning***/Keras/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hbRj_hvAuO08"
   },
   "source": [
    "#**Calc DR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ydedQyLr1IM-"
   },
   "outputs": [],
   "source": [
    "def create_batch(x, y, batch_size):\n",
    "    a = list(range(len(x)))\n",
    "    np.random.shuffle(a)\n",
    "    x = x[a]\n",
    "    y = y[a]\n",
    "\n",
    "    batch_x = [x[batch_size * i : (i+1)*batch_size,:].tolist() for i in range(len(x)//batch_size)]\n",
    "    batch_y = [y[batch_size * i : (i+1)*batch_size].tolist() for i in range(len(x)//batch_size)]\n",
    "    return np.array(batch_x), np.array(batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6757,
     "status": "ok",
     "timestamp": 1594948971540,
     "user": {
      "displayName": "Tien LE KHAC",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhATILfEwLuvrRlBGPMrmY7nclZNsxGKzoqqHB_Cg=s64",
      "userId": "18298916241916904857"
     },
     "user_tz": -420
    },
    "id": "3XnDlpDauT4O",
    "outputId": "457caca2-9e2a-481c-8e22-5bce568cc97a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "CALCULATE DETECTION RATE\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model: CNN, Attack Category: DOS\n",
      "Testset\n",
      " - Amount of Normal record: 9711\n",
      " - Amount of DOS record: 7460\n",
      " -> DOS - DR: 81.73%\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model: CNN, Attack Category: U2R_AND_R2L\n",
      "Testset\n",
      " - Amount of Normal record: 9711\n",
      " - Amount of U2R_AND_R2L record: 2952\n",
      " -> U2R_AND_R2L - DR: 0.13%\n"
     ]
    }
   ],
   "source": [
    "# Calc DR\n",
    "print(f\"{100*'='}\\nCALCULATE DETECTION RATE\")\n",
    "for attack_category in ['DOS', 'U2R_AND_R2L']:\n",
    "    print(f\"{100*'-'}\\nModel: CNN, Attack Category: {attack_category}\")\n",
    "    \n",
    "    # Load Data\n",
    "    print(\"Testset\")\n",
    "    x_test, y_test = load_dataset_only(testset_path,attack_category)\n",
    "    batch_x_test, batch_y_test = create_batch(x_test, y_test, batch_size = 128)\n",
    "    \n",
    "\n",
    "    # Load Model\n",
    "    model_saved_name = str(f\"created_date_{today}_CNN.h5\")\n",
    "    ids_model_path = str(f\"{save_model_path}{attack_category}Deep_Learning/Keras/{model_saved_name}\")\n",
    "    ids_model = load_model(ids_model_path)\n",
    "    # ids_model.summary()\n",
    "\n",
    "    # Test & Calc DR\n",
    "    drs = []\n",
    "    for idx, data in enumerate(batch_x_test):\n",
    "        true_labels = batch_y_test[idx]\n",
    "        data = data.reshape(data.shape[0], 41, 1)\n",
    "        ids_outputs = ids_model.predict(data)\n",
    "        predict_labels = np.argmax((ids_outputs),axis = 1)\n",
    "\n",
    "        tn, fn, fp, tp = confusion_matrix(true_labels,predict_labels).ravel()\n",
    "\n",
    "        drs.append(tp/(tp + fp))\n",
    "    dr = np.mean(drs)*100\n",
    "    print(f\" -> {attack_category} - DR: {dr:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CNN",
   "provenance": [
    {
     "file_id": "1lXJCpzo6EaMXbdbm0DWKgckhdo8QJ2WD",
     "timestamp": 1592964124705
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
